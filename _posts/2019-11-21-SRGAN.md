---
layout: post
title: Study SRGAN
date: 2019-11-21 13:34
summary: Summary Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network
categories: jekyll pixyll
---

# Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network
###### Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi; The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 4681-4690

---

## Abstract
 * 기존에 존재하는 깊고 빠른 CNN을 사용하여 단일 이미지 super-resolution의 속도와 정확성 향상에도 불구하고 여전히 해결되지 않은 큰 문제가 있다.
 * 큰 Upscaling 요소에서 super-resolve을 할 때 ___<span style="color:red">더 미세한 텍스처 디테일을 어떻게 복구할 것인가에 대해서 이다.</span>___
 * 최근 연구는 평균 제곱 재구성 오류(mean squared reconstruction error)를 최소화하는데 주로 초점을 맞췄다.
 * 결과 추정 값들은 피크 신호 대 잡음비(PSNR)가 높지만 종종 고주파 세부 정보(high-frequency detail)가 부족하고 더 높은 해상도에서 기대되는 충실도와 일치하지 않다는 관점에서 만족스럽지 못한다.
  * __해당 방법들(PSNR,MSE)로 측정한 것들이 수치상일 뿐 정확한 측정법이 아니다.__
 * 해당 논문에서는 이미지를 고해상도로 만들기 위한 GAN인 __SRGAN(Super-resolution generative adversarial network)__ 을 소개한다.
 * 우리가 아는 한, SRGAN은 4배 확대 요소에 대해서 사실적이게 자연스러운 이미지 추론할 수 있는 최초의 프레임워크이다. (2017년도 기)
 * 이를 위해 adversarial loss와 content loss로 구성된 __perceptual loss function__ 을 제안한다.
 * Adversarial loss는 초 해상도 이미지와 원본 이미지를 구별하도록 훈련 된 판별기(discriminator) 네트워크를 사용하여 솔루션을 자연 스러운 이미지로 만들수 있도록 한다.
 * 또한 픽셀 공간의 유사성 대신 perceptual 유사성에 의해 유발 된 content loss를 사용합니다.
 * SRGAN으로 얻은 __MOS(mean-opinion-score)__ 점수는 최첨단 방법으로 얻은 것보다 원본 고해상도 이미지의 점수에 더 가깝게 나타났다.

---

## Introduction
 * __저해상도(LR)에서 고해상도(HR)이미지를 추정하는 매우 어려운 작업을 SR(Super-resolution)이라고 한다.__
 * SR은 컴퓨터 비전 연구 커뮤니티에서 상당한 관심을 받았으며 광범위한 응용 프로그램을 보유하고 있다.
 * Supervised SR알고리즘의 최적화 목표는 일반적으로 복구 된 HR이미지와 정답 사이의 __MSE(mean squared error)__ 를 최소화하는 것입니다.
 * 이는 MSE를 최소화하면 SR 알고리즘을 평가하고 비교하는 데 사용되는 일반적인 측정치인 __PSNR(peak signal-to-noise ratio)__ 를 최대화하기 때문에 편리합니다.
 * 그러나 높은 텍스처 디테일과 같이 지각적으로 관련된 차이를 캡처하는 MSE의 기능은 픽셀 단위 이미지 차이를 기반으로 정의되므로 매우 제한적이다.
 * 이는 아래 그림에 나와 있으며, 가장 높은 PSNR이 지각적으로 더 나은 SR 결과를 반영 할 필요는 없다.

![_config.yml](https://dongyyyyy.github.io/images/SRGAN/Figure2.JPG)

 * __PSNR이 높을수록 원본 이미지와 차이가 적다는 것을 의미하는데 위의 그림을 보면 PSNR이 가장 낮은 SRGAN이 육안으로 봤을 때 가장 원본 이미지와 유사함을 느낄 수 있다.__
 * __그렇기에 논문에서 PSNR과 MSE가 디테일에 관련된 부분을 생각하면 절대적인 측정 방법이 아님을 언급한다.__
 * 이 작업에서 우리는 __skip-connection__ 이 있는 깊은 __residual network(ResNet)__ 을 사용하고 MSE에서 유일한 최적화 대상으로 분기하는 __super-resolution GAN(SRGAN)__ 을 제안한다.
 * 이전 연구와 달리, 우리는 HR 참조 이미지와 지각적으로 어려운 솔루션을 장려하는 판별기와 결합 된 VGG network의 high-level feature maps을 사용하여 새로운 loss functiond을 정의합니다.
  * __<span style="color:red">기존의 경우에는 generator을 통해 만들어진 SR이미지와 HR이미지를 다른 전처리 없이 MSE를 통해 loss를 구했는데 이 방식은 shift와 같은 상황에 대해서 취약한 부분이 존재했기에 이를 해결하기 위해서 VGG network를 평가모델로 사용하여 추출된 feature map을 사용하여 loss를 계산하는 방식을 활용함</span>__

---

## Related works

### Image super-resolution
 * 기존에 SR을 하기 위한 방버들은 많이 있었다.
 * 최근에 CNN기반의 SR 알고리즘이 굉장히 높은 성능을 보였다.
 * Bicubic 보간(interpolation)을 사용하여 입력 이미지를 up scale하고 3개의 deep fully convolutional network를 end-to-end로 만들어서 학습시켜 높은 성능을 얻었다.
 * 속도와 정확도를 높이기 위해 추가적인 방법들이 제안되었다.

### Design CNN
 * 컴퓨터 비전 문제 대다수는 CNN으로 해결하고 있다.
 * Deeper network architectures은 학습하기 어렵지만 매우 높은 복잡성의 모델 매핑을 허락하고 네트워크의 정확성을 높여주는 잠재성을 가지고 있다.
 * 이러한 deeper network architectures를 효율적으로 훈련시키기 위해 __batch-norm__ 을 사용하여 내부 co-variate shift에 대응한다.
 * 또 다른 최근에 소개된 개념은 __residual blocks__ 와 __skip-connection__ 이다.
 * skip-connection은 본질적으로 사소한 identity 매핑 모델링의 네트워크 아키텍처를 완화하지만, 잠재적으로 convolutional kernel로 표현하는 것은 쉽지 않다.

 ![_config.yml](https://dongyyyyy.github.io/images/SRGAN/resnet_block.jpg)

 * SISR(Single Image Super Resolution)의 맥락에서, up scale 필터를 학습하는 것이 정확성 및 속도 측면에서 유리하다는 것이 밝혀졌다.

### Loss function
 * 결과를 바로 MSE하는 것이 아닌 VGG19와 같은 Network를 통해서 추출된 값을 사용하여 Loss 계산을 하는 것이 효율적이라는 것이 밝혀졌다.
 * 이와 같은 내용에 대해서 연구하는게 많아지고 있다.

---

## Method
![_config.yml](https://dongyyyyy.github.io/images/SRGAN/Method.JPG)

![_config.yml](https://dongyyyyy.github.io/images/SRGAN/Loss.JPG)

---


## Adversarial network architectures
![_config.yml](https://dongyyyyy.github.io/images/SRGAN/Discriminator_loss.jpg)

### Generator & Discriminator Network architecture
![_config.yml](https://dongyyyyy.github.io/images/SRGAN/Discriminator_Ganerator.JPG)

---

## Perceptual loss function
![_config.yml](https://dongyyyyy.github.io/images/SRGAN/Perceptual_loss_function.jpg)

### Content loss
#### Without VGG Network
![_config.yml](https://dongyyyyy.github.io/images/SRGAN/MSE_Loss_function.jpg)

#### With VGG Network
![_config.yml](https://dongyyyyy.github.io/images/SRGAN/paper_content_loss.jpg)
